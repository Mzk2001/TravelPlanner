import { useState, useRef, useCallback } from 'react';

interface VoiceRecorderState {
  isRecording: boolean;
  isProcessing: boolean;
  error: string | null;
  transcript: string | null;
}

interface VoiceRecorderReturn extends VoiceRecorderState {
  startRecording: () => void;
  stopRecording: () => void;
  clearError: () => void;
  clearTranscript: () => void;
}

export const useVoiceRecorder = (): VoiceRecorderReturn => {
  const [state, setState] = useState<VoiceRecorderState>({
    isRecording: false,
    isProcessing: false,
    error: null,
    transcript: null,
  });

  const recognitionRef = useRef<SpeechRecognition | null>(null);

  const startRecording = useCallback(async () => {
    try {
      console.log('ðŸŽ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«...');
      setState(prev => ({ ...prev, error: null, transcript: null }));

      // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒWeb Speech API
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        console.error('âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeã€Edgeæˆ–Safariæµè§ˆå™¨');
      }

      console.log('âœ… æµè§ˆå™¨æ”¯æŒè¯­éŸ³è¯†åˆ«');

      // åˆ›å»ºè¯­éŸ³è¯†åˆ«å®žä¾‹
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognitionRef.current = recognition;

      // é…ç½®è¯­éŸ³è¯†åˆ«å‚æ•°
      recognition.continuous = false; // ä¸è¿žç»­è¯†åˆ«
      recognition.interimResults = true; // è¿”å›žä¸­é—´ç»“æžœï¼Œè¿™æ ·å¯ä»¥çœ‹åˆ°å®žæ—¶è¯†åˆ«
      recognition.lang = 'zh-CN'; // ä¸­æ–‡è¯†åˆ«
      recognition.maxAlternatives = 1; // åªè¿”å›žæœ€ä½³ç»“æžœ

      console.log('ðŸ”§ è¯­éŸ³è¯†åˆ«é…ç½®å®Œæˆ');

      // è¯†åˆ«ç»“æžœå¤„ç†
      recognition.onresult = (event) => {
        console.log('ðŸŽ¯ è¯­éŸ³è¯†åˆ«ç»“æžœ:', event);
        let finalTranscript = '';
        let interimTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        console.log('ðŸ“ æœ€ç»ˆç»“æžœ:', finalTranscript);
        console.log('â³ ä¸­é—´ç»“æžœ:', interimTranscript);

        if (finalTranscript) {
          setState(prev => ({ 
            ...prev, 
            isRecording: false, 
            isProcessing: false,
            transcript: finalTranscript
          }));
        } else if (interimTranscript) {
          // æ˜¾ç¤ºä¸­é—´ç»“æžœ
          setState(prev => ({ 
            ...prev, 
            transcript: interimTranscript + '...'
          }));
        }
      };

      // è¯†åˆ«ç»“æŸå¤„ç†
      recognition.onend = () => {
        console.log('ðŸ è¯­éŸ³è¯†åˆ«ç»“æŸ');
        setState(prev => ({ ...prev, isRecording: false, isProcessing: false }));
      };

      // è¯†åˆ«é”™è¯¯å¤„ç†
      recognition.onerror = (event) => {
        console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        let errorMessage = 'è¯­éŸ³è¯†åˆ«å¤±è´¥';
        
        switch (event.error) {
          case 'no-speech':
            errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡æ–°å°è¯•';
            break;
          case 'audio-capture':
            errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£Žï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®';
            break;
          case 'not-allowed':
            errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£Ž';
            break;
          case 'network':
            errorMessage = 'ç½‘ç»œè¿žæŽ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥';
            break;
          case 'aborted':
            errorMessage = 'è¯­éŸ³è¯†åˆ«è¢«ä¸­æ–­';
            break;
          default:
            errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`;
        }
        
        setState(prev => ({ 
          ...prev, 
          error: errorMessage,
          isRecording: false,
          isProcessing: false
        }));
      };

      // è¯†åˆ«å¼€å§‹å¤„ç†
      recognition.onstart = () => {
        console.log('ðŸš€ è¯­éŸ³è¯†åˆ«å¼€å§‹');
        setState(prev => ({ ...prev, isProcessing: true }));
      };

      // å¼€å§‹è¯†åˆ«
      console.log('ðŸŽ¯ å¯åŠ¨è¯­éŸ³è¯†åˆ«...');
      recognition.start();
      
      setState(prev => ({ ...prev, isRecording: true }));

    } catch (error) {
      console.error('âŒ å¼€å§‹è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      setState(prev => ({ 
        ...prev, 
        error: error instanceof Error ? error.message : 'æ— æ³•å¯åŠ¨è¯­éŸ³è¯†åˆ«',
        isRecording: false 
      }));
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (recognitionRef.current && state.isRecording) {
      recognitionRef.current.stop();
    }
  }, [state.isRecording]);

  const clearError = useCallback(() => {
    setState(prev => ({ ...prev, error: null }));
  }, []);

  const clearTranscript = useCallback(() => {
    setState(prev => ({ ...prev, transcript: null }));
  }, []);

  return {
    ...state,
    startRecording,
    stopRecording,
    clearError,
    clearTranscript,
  };
};
